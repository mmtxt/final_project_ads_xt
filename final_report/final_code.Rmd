---
title: "Hurricane Harvey in America "
author: xueting tao
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Getting the data
```{r eval=FALSE}
#just for reference use
#getting the data: install twitterR since install.pacakge("twitterR")is not avialble
#let me try another one
install.packages(c("devtools", "rjson", "bit64", "httr"))
#follow the instruction and restart R
library(devtools)
install_github("geoffjentry/twitteR")

library(twitteR)
setup_twitter_oauth("API key", 
                    "API secret",
                    "Access token",
                    "Access secret")
#selection:
1

#load useful package
library(dplyr)
library(stringr)
library(rebus)
library(tidyr)
library(ggplot2)
library(ggmap)
library(mapproj)
library(twitteR)

#start getting the data
#data at 9-4
sample_9_4<-searchTwitter('#HurricaneHarvey until:2017-9-5', n=10000)
#data at 9-5
sample_9_5<-searchTwitter('#HurricaneHarvey until:2017-9-6', n=10000)
#data at 9-6
sample_9_6<-searchTwitter('#HurricaneHarvey until:2017-9-7', n=10000)
#data at 9-7
sample_9_7<-searchTwitter('#HurricaneHarvey until:2017-9-8', n=10000)
#data at 9-8
sample_9_8<-searchTwitter('#HurricaneHarvey until:2017-9-9', n=10000)
HH9_4<-twListToDF(sample_9_4)
HH9_5<-twListToDF(sample_9_5)
HH9_6<-twListToDF(sample_9_6)
HH9_7<-twListToDF(sample_9_7)
HH9_8<-twListToDF(sample_9_8)

#collect correction data(using a as a key word to search)
HH9_29<-searchTwitter('a until:2017-9-30 ',n=10000)
HH9_29<-twListToDF(HH9_29)
```

Data cleaning

```{r }
#load useful package
library(dplyr)
library(stringr)
library(rebus)
library(tidyr)
library(ggplot2)
library(ggmap)
library(mapproj)
library(twitteR)
library(cowplot)

#In order to make sure about reproduction, let's just use my data
#download the data from the dropbox

download.file("https://www.dropbox.com/s/26fciujm2iw3umu/9-4.csv?dl=1","9-4.csv")
download.file("https://www.dropbox.com/s/h58yrmd1cy0mwgb/9-5.csv?dl=1","9-5.csv")
download.file("https://www.dropbox.com/s/vzselkdqr597ykk/9-6.csv?dl=1","9-6.csv")
download.file("https://www.dropbox.com/s/l4i5ufbxemu241b/9-7.csv?dl=1","9-7.csv")
download.file("https://www.dropbox.com/s/fb2hv24etxytxgl/9-8.csv?dl=1","9-8.csv")
download.file("https://www.dropbox.com/s/xqb3bqnmv87olh0/9-29.csv?dl=1","9-29.csv")

#read in the data:
for(i in c(4:8,29)){
  assign(paste("HH9",i,sep="_"),
         read.csv(paste("9-",i,".csv",sep=""))[,-1])
  
}

#start working:
# Delete lines without location information in the original dataset and create new dataset called cHHs.
#select data that have location information

for(i in c(4:8,29)){
 cHHs<-get(paste("HH9",i,sep="_"))
 cHHs$location[cHHs$location==""]<-NA  
 cHHs$location<-as.factor(cHHs$location)
 cHHs<-filter(cHHs,!is.na(location))
 write.csv(cHHs,paste("c9-",i,".csv",sep=""))
 assign(paste("cHH9",i,sep="_"),cHHs)
 rm(cHHs)
}
#explore the raw data:
for (i in c(4:8,29)){
  dim<-get(paste("cHH9",i,sep="_"))
  assign(paste("dim",i,sep=""),dim(dim))
}
#first step data visualing:
dim<-c(dim4,dim5,dim6,dim7,dim8,dim29)
col<-c("observation_num","variable_num")
row<-c("9-4","9-5","9-6","9-7","9-8","9-29")
dim_max<-matrix(dim,byrow = TRUE,nrow=6)
rownames(dim_max)<-row
colnames(dim_max)<-col
(dim_max<-data.frame(dim_max))
write.csv(dim_max,"dim.csv")
dim<-read.csv("dim.csv")
colnames(dim)[1]<-"dates"
dim

#In order to continue analysis, I need first clean the format of the data, seperate the location information by city and state, showing all the charachers in upper form and cleaning the spaces. After that, I seperate the dataset into two part, the one with useful state information and the one without useful state information.

#seperate the location information into state and city,export those data with state information
for(i in c(4:8,29)){
  temp<-get(paste("cHH9",i,sep="_"))
  temp<-separate(temp,location,c("city","state"),sep=",")
  temp$state<-toupper(temp$state)
  temp$city<-toupper(temp$city)
  temp$state<-as.factor(str_replace_all(temp$state,pattern=" ",replacement=""))
  temp$city<-as.factor(str_replace_all(temp$city,pattern=" ",replacement=""))
  assign(paste("cHH9",i,sep="_"),temp)
  write.csv(temp,paste("c9-",i,".csv",sep=""))
}


# I calculated the time each city shows in TX and LA, both in the data that containing a state information and without state information. Add state information to the final dataframe


for(i in c(4:8,29)){
  
  temp<-get(paste("cHH9",i,sep="_"))
  y_state<-filter(temp,state!="USA"
                  &!is.na(state))
  y_state_1<-filter(y_state,state=="TX"|state=="TEXAS")
  y_state_2<-filter(y_state,state=="LA"|state=="LOUISIANA")
  y_state_3<-filter(y_state,state=="MA"|state=="MASSACHUSETTS")
  y_state_4<-filter(y_state,state=="NV"|state=="NEVADA")
                  
  for(a in 1:4){
    assign(paste("city_c",a,sep="_"),
           summary(get(paste("y_state",a,sep="_"))$city,
                   maxsum = 1000))
    assign(paste("name_city",a,sep="_"),
           names(get(paste("city_c",a,sep="_"))))
    assign(paste("city_ystate",a,sep="_"),
           data.frame(get(paste("city_c",a,sep="_"))))
    temp2<-get(paste("city_ystate",a,sep="_"))
    temp2$city<-as.factor(get(paste("name_city",a,sep="_")))
    
    #add colnames
    colnames(temp2)<-c("number","city")
    assign(paste("city_ystate",a,sep="_"),
           temp2)
  }
  city_ystate_1$state<-as.factor("TX")
  city_ystate_2$state<-as.factor("LA")
  city_ystate_3$state<-as.factor("MA")
  city_ystate_4$state<-as.factor("NV")
  city_ystate<-rbind(city_ystate_1,city_ystate_2,city_ystate_3,city_ystate_4)
  
#clear nonsense data$rename
  city_ystate<-filter(city_ystate,number>0)  
#calculate frequency
  city_ystate$freq<-city_ystate[ ,"number"]/sum(city_ystate[ ,"number"])
#add date value
  city_ystate$date<-paste("9",i,sep="-")
#reorder
  city_ystate<-city_ystate[order(-city_ystate$number), ]
#save the data
  write.csv(city_ystate,paste("citys_9_",i,".csv",sep=""))
  rm(city_ystate)
  rm(city_ystate_1)
  rm(city_ystate_2)
  rm(city_ystate_3)
  rm(city_ystate_4)
  rm(temp)
  rm(temp2)
  rm(y_state)
  rm(y_state_1)
  rm(y_state_2)
  rm(y_state_3)
  rm(y_state_4)
}

```


Results:
```{r}
###############################1. basic comparasion:#########################################################

#read in the dataset
for(i in c(4:8,29)){
  
  temp<-read.csv(paste("citys_9_",i,".csv",sep=""))
  temp<-temp[ ,-1]
  assign(paste("citys_9",i,sep="_"),temp)
  
}

#adjusting:
##extract first 40 cities and adjust them with 9_29:
for (i in c(4:8,29)){
  
  head_city<-head(get(paste("citys_9",i,sep="_")),40)
  head_city$freq<-head_city[ ,"number"]/sum(head_city[ ,"number"])
  assign(paste("head",i,sep=""),head_city)
}
for (i in 4:8){
  
  head<-get(paste("head",i,sep=""))
  head_re<-merge(x=head,y=head29,by="city",all.x=TRUE)
  head_cl<-head_re %>%
    select(city,freq.x,freq.y,state.x) %>%
    arrange(desc(freq.x))
  head_cl[is.na(head_cl)]<-0
  head_cl<-head_cl %>%
    mutate(freq_ad=freq.x-freq.y) %>%
    filter(freq_ad>0) %>%
    arrange(desc(freq_ad))
  write.csv(head_cl,paste("adcity_9_",i,".csv",sep=""))
}

##read in the adjust data:
for (i in 4:8){
  assign(paste("adcity_9_",i,sep=""),read.csv(paste("adcity_9_",i,".csv",sep=""))[,-1])
}


#ten high cities based on different dates:
##lists:
###raw data before adjusting
for (i in 4:8){
  rawrow<-get(paste("citys_9_",i,sep=""))
  rawrow<-rawrow$city[c(1:20)]
  assign(paste("rawrow",i,sep=""),as.character(rawrow))
}

city<-c(rawrow4,rawrow5,rawrow6,rawrow7,rawrow8)
col<-c("citys","date")
row<-c("9-4","9-5","9-6","9-7","9-8")
city_max<-matrix(city,byrow = FALSE,ncol=5)
colnames(city_max)<-row
write.csv(city_max,"rawcity.csv")
(raw_city_list<-read.csv("rawcity.csv"))

###raw data after adjusting
for (i in 4:8){
  adrow<-get(paste("adcity_9_",i,sep=""))
  adrow<-adrow$city[c(1:20)]
  assign(paste("adrow",i,sep=""),as.character(adrow))
}

city<-c(adrow4,adrow5,adrow6,adrow7,adrow8)
col<-c("citys","date")
row<-c("9-4","9-5","9-6","9-7","9-8")
city_max<-matrix(city,byrow = FALSE,ncol=5)
colnames(city_max)<-row
write.csv(city_max,"adcity.csv")
(adjust_city_list<-read.csv("adcity.csv"))


##bar-plot:
###Before adjusting:
a<-0
for (i in c(4:8,29)){
  a<-a+1
  city_ystate<-get(paste("citys_9",i,sep="_"))
  city_ystate$city<-factor(city_ystate$city, levels=unique(city_ystate$city))
  assign(paste("p",a,sep=""),ggplot(head(city_ystate,20),aes(x=city,y=freq,fill=state))+
         geom_bar(stat = "identity")+
         labs(title=paste("Top 10 cities in Sep/",i,"th"," before adjustion", sep=""))+
         coord_flip())
}
plot_grid(p1,p2,p3,p4,p5, ncol = 2)

###Data after adjusting:

b<-0
for (i in c(4:8)){
  b<-b+1
  city_ystate<-get(paste("adcity_9",i,sep="_"))
  city_ystate$city<-factor(city_ystate$city, levels=unique(city_ystate$city))
  assign(paste("e",b,sep=""),ggplot(head(city_ystate,10),aes(x=city,y=freq_ad,fill=state.x))+
           geom_bar(stat = "identity")+
           labs(title=paste("September ",i,"th",sep=""))+
           ylab("freqency")+
           theme(axis.title.x = element_text(size = 5),
                 axis.title.y=element_text(size=5),
                 axis.text.y=element_text(size = 4),
                 axis.text.x=element_text(size=4),
                 plot.title=element_text(size=5),
                 legend.key.size=unit(.045,"inches"),
                 legend.key.height=unit(.05,"inches"),
                 legend.key.width = unit(.05,"inches"),
                 legend.title=element_text(size=4),
                 legend.text=element_text(size=4))+
           coord_flip())
}
plot_grid(e1,e2,e3,e4,e5, ncol = 2)
ggsave("adjust_plot.png")

################################################################2 Graphing########################


#using ggmap package and ggplot to graph the area on the map as to visualize the data.
library(ggmap)
library(mapproj)



#fit geo information:
for (i in 4:8){
  location<-get(paste("adcity_9",4,sep="_"))
  
  location$longi<-NA
  location$latti<-NA

  for(a in 1:nrow(location)){
    location[a, 6:7] <- geocode(as.character(location[a,"city"])) %>% as.numeric
  }
  
  #for those not fitted in the first loop
  for(b in 1:nrow(location)){
    if(is.na(location[b, 7])){
      location[b, 6:7] <- geocode(as.character(location[i,"city"])) %>% as.numeric
    }
    else{}
  }
  location<-filter(location,!is.na(longi))
  location<-filter(location,longi<=-60&longi>=-140&latti>=20&latti<=50)
  assign(paste("adcity_9",i,sep="_"),location)
  write.csv(location,paste("loc_9_",i,".csv",sep=""))
} 


# Using the ggmap package, showing the result. The code I used is as below

#read in the datasete
  for(i in 4:8) {
    
    loc<-read.csv(paste("loc_9_",i,".csv",sep=""))
    loc<-loc[ ,-1]
    assign(paste("loc_9",i,sep="_"),loc)
  }
statemap<-get_map(location='Texas',zoom=6,maptype="toner")
statemap<-ggmap(statemap)

b<-0
for (i in 4:8){
  b<-b+1
  location<-get(paste("loc_9",i,sep="_"))
  texas<-filter(location,state.x=="TX"|state.x=="LA")
  assign(paste("gb",b,sep=""),
         statemap +  geom_point(aes(x=longi, y = latti), data = texas,
                                alpha=0.2, col="yellow",size = texas$freq_ad*200)+
                     geom_point(aes(x = longi, y = latti), data = texas, 
                                alpha = 0.6, col = "red", size = 0.5) +
                     theme(axis.title.x = element_text(size = 5),
                           axis.text.x=element_text(size = 5),
                           axis.title.y = element_text(size = 5),
                           axis.text.y=element_text(size = 5),
                           text = element_text(size = 10),
                           plot.title=element_text(size=4))+
                     labs(title=paste("Sep/",i,"th",sep=""))+
                     scale_size_continuous(range = range(texas$number)))
                     
}
plot_grid(gb1, gb2, gb3, gb4,gb5, cols=2)
ggsave("map_move.png",limitsize = FALSE)



```

